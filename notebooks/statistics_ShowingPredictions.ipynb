{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ecec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adapted from ExploringDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae7aaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os, errno\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from Instseg_model import MultiLayerFastLocalGraphModelV2 as model1\n",
    "from dataset import pcloader\n",
    "from graph_generation import gen_multi_level_local_graph_v3\n",
    "\n",
    "from math import floor, ceil\n",
    "from scipy.stats import mode\n",
    "\n",
    "import open3d as o3d\n",
    "from plot_utils import add_staple_patch\n",
    "from utils import parse_labelfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78c9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASSIFICATION INFERENCE\n",
    "\n",
    "## High Level Config Settings\n",
    "\n",
    "graph_gen_kwargs = {\n",
    "\t'add_rnd3d': True,\n",
    "\t'base_voxel_size': 0.8,\n",
    "\t'downsample_method': 'random',\n",
    "\t'level_configs': [\n",
    "\t\t{'graph_gen_kwargs': {'num_neighbors': 64, 'radius': 0.4},\n",
    "\t\t 'graph_gen_method': 'disjointed_rnn_local_graph_v3',\n",
    "\t\t 'graph_level': 0,\n",
    "\t\t 'graph_scale': 1},\n",
    "\t\t{'graph_gen_kwargs': {'num_neighbors': 192, 'radius': 1.2},\n",
    "\t\t 'graph_gen_method': 'disjointed_rnn_local_graph_v3',\n",
    "\t\t 'graph_level': 1,\n",
    "\t\t 'graph_scale': 1}]\n",
    "}\n",
    "\n",
    "def configure_model(model_params_path, max_cls_classes=3, max_inst_classes=7, verbose=False):\n",
    "    a = time.time()\n",
    "    model = model1(num_classes=max_cls_classes, max_instance_no=max_inst_classes)\n",
    "    if os.path.isfile(model_params_path):\n",
    "        model.load_state_dict(torch.load(model_params_path))\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"[ModelParamPathError] {model_params_path} does not exist\")\n",
    "        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), model_params_path)\n",
    "    b = time.time()\n",
    "    if verbose:\n",
    "        print(f\"Model Setup Time (secs) : {b-a}\")\n",
    "    return model\n",
    "\n",
    "def classify_scan(model, scan_path, verbose=False):\n",
    "    \"\"\"\n",
    "    Returns \n",
    "     - the x|y|z|cls|inst for all keypoints in the cloud as a Kx5 array\n",
    "     - and also as a dict\n",
    "    \"\"\"\n",
    "    a = time.time()\n",
    "    pointxyz, offset = pcloader(scan_path)\n",
    "    vertex_coord_list, keypoint_indices_list, edges_list = \\\n",
    "    gen_multi_level_local_graph_v3(pointxyz,0.6,graph_gen_kwargs['level_configs'])\n",
    "    last_layer_v = vertex_coord_list[-1]\n",
    "\n",
    "    ## conversions: type precision\n",
    "    vertex_coord_list = [p.astype(np.float32) for p in vertex_coord_list]\n",
    "    keypoint_indices_list = [e.astype(np.int32) for e in keypoint_indices_list]\n",
    "    edges_list = [e.astype(np.int32) for e in edges_list]\n",
    "\n",
    "    ## conversions: numpy array to tensor\n",
    "    vertex_coord_list = [torch.from_numpy(item) for item in vertex_coord_list]\n",
    "    keypoint_indices_list = [torch.from_numpy(item).long() for item in keypoint_indices_list]\n",
    "    edges_list = [torch.from_numpy(item).long() for item in edges_list]\n",
    "\n",
    "    ## Run graph through GNN model\n",
    "    batch = (vertex_coord_list, keypoint_indices_list, edges_list)\n",
    "    cls_seg, inst_seg = model(*batch)\n",
    "\n",
    "    ## Filter classification probabilities for the most probable\n",
    "    cls_preds = torch.argmax(cls_seg, dim=1)\n",
    "    inst_preds = torch.argmax(inst_seg, dim=1)\n",
    "    \n",
    "    ## expand the shape of the array\n",
    "    cls_preds = np.expand_dims(cls_preds, axis=1)\n",
    "    inst_preds = np.expand_dims(inst_preds, axis=1)\n",
    "\n",
    "    b = time.time()\n",
    "    if verbose:\n",
    "        print(\"Scan Inference Time (secs): \", b-a)\n",
    "        print()\n",
    "    \n",
    "    return np.hstack((last_layer_v, cls_preds, inst_preds)),\\\n",
    "            {'vertices': last_layer_v, 'cls_preds': cls_preds, 'inst_preds': inst_preds}\n",
    "\n",
    "def filter_out_background(scan_data):\n",
    "    non_bg_idx = ~np.logical_or(scan_data[:, 3] == 0, scan_data[:, 4] == 0)\n",
    "    non_bg = scan_data[non_bg_idx]\n",
    "    return non_bg, non_bg_idx\n",
    "\n",
    "def count_cluster_by_instance_prediction(scan_data, threshold_factor=0.5):\n",
    "    \"\"\"\n",
    "    Returns a cluster_count ie the number of clusters on the cls field/col that has at least a threshold number of members\n",
    "    Also: a dict of intermediary/final counts, types and thresholds\n",
    "    \"\"\"\n",
    "    inst, inst_count = np.unique(scan_data[:,4], return_counts=True)\n",
    "    inst_count_threshold = threshold_factor * np.mean(inst_count)\n",
    "    reduced_idx = np.where(inst_count > inst_count_threshold)\n",
    "    cluster_count = np.sum(inst_count > inst_count_threshold)\n",
    "    reduced = inst[reduced_idx]\n",
    "    \n",
    "    return cluster_count, {'orig_insts': inst,\n",
    "                           'orig_inst_ct': inst_count,\n",
    "                           'inst_ct_thresh': inst_count_threshold,\n",
    "                           'reduced_insts': reduced}\n",
    "def draw_labels(welds, ax):\n",
    "    for weld in welds:\n",
    "        markers = add_staple_patch(ax ,weld['xloc'], weld['yloc'], weld[\"yaw\"], weld['cls'] )\n",
    "        \n",
    "def _plot(path, points, values, title=\"\", caption=\"\", overlay_points=None, labels_dict=None ):\n",
    "    \"\"\"\n",
    "    path - output path\n",
    "    points - matrix of x, y, etc cols\n",
    "    values - assigned value per point ie predicted/truth cls/inst\n",
    "    [optional] overlay_points = [{\"xs\":[], \"ys\":[], \"cs\":_, \"marker\":_, \"label\"=_}, ...]\n",
    "    labels_dict - to overlay the staple patch\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    im = ax.scatter(points[:,0], points[:,1],s=0.25,c=values)\n",
    "    \n",
    "\n",
    "    if overlay_points:    \n",
    "        for pts in overlay_points:\n",
    "            _im = ax.scatter(pts[\"xs\"], pts[\"ys\"], s=pts[\"ss\"], c=pts[\"cs\"], marker=pts[\"marker\"])\n",
    "    \n",
    "    if labels_dict:\n",
    "        draw_labels(labels_dict[\"welds\"], ax)\n",
    "            \n",
    "    ax.set_xlabel(\"x [mm]\")\n",
    "    ax.set_ylabel(\"y [mm]\")\n",
    "\n",
    "        \n",
    "    legend_ = ax.legend(*im.legend_elements(), bbox_to_anchor=(1.1, 1), loc=\"upper right\")\n",
    "    ax.add_artist(legend_)\n",
    "\n",
    "    ax.text(0.5, -0.5, caption, style='italic', \\\n",
    "        horizontalalignment='center', verticalalignment='top', transform=ax.transAxes)\n",
    "    axes=plt.gca()\n",
    "    axes.set_aspect(1)\n",
    "    if path:\n",
    "        plt.savefig(path, dpi=150)\n",
    "        plt.close()\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "    else:\n",
    "        plt.show\n",
    "    \n",
    "def save_prediction_plots(non_bg_matrix, labels_dict=None, cls_tag=None, inst_tag=None, cls_col=3, inst_col=4, inst_seg_dir_path=\"./plots/inst/\", cls_seg_dir_path=\"./plots/cls/\", verbose=False):\n",
    "    \"\"\"\n",
    "    non_bg_matrix -- x|y|z|cls|inst\n",
    "    // tag -- eg A_xycls_eps0_45_50\n",
    "    tag -- eg A_xycls\n",
    "    \"\"\"\n",
    "    \n",
    "    ## [RED FLAG] - what if dir_path comes through as None\n",
    "    f_tag = \"[save_prediction_plots]\"\n",
    "    f_msg = []\n",
    "    \n",
    "    if not (cls_tag and inst_tag):\n",
    "        print(\"[ERROR] No specfied cls_tag or inst_tag args. Plots not generated\")\n",
    "    else:\n",
    "        if cls_tag:\n",
    "            cls_output_path = cls_seg_dir_path+cls_tag+\".png\" if cls_seg_dir_path else None\n",
    "            _plot(cls_output_path, non_bg_matrix[:, :2], non_bg_matrix[:, cls_col], title=cls_tag, labels_dict=labels_dict)\n",
    "            f_msg.append(cls_output_path)\n",
    "\n",
    "        if inst_tag:\n",
    "            inst_output_path = inst_seg_dir_path+inst_tag+\".png\" if inst_seg_dir_path else None\n",
    "            _plot(inst_output_path, non_bg_matrix[:, :2], non_bg_matrix[:, inst_col], title=inst_tag, labels_dict=labels_dict)\n",
    "            f_msg.append(inst_output_path)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{f_tag}: Done --> {f_msg}\")\n",
    "            \n",
    "\n",
    "\n",
    "###################################################\n",
    "###  EVENTUALLY BUT SKIPPING THIS FOR NOW #########\n",
    "## Need to record the model weights version\n",
    "## Need to record the number of instances identified, the instance_seg_loss and cls_loss\n",
    "def save_prediction_stats(model, scan_path, output_file):\n",
    "    \"\"\"\n",
    "    Intialize text file if non-existent with name | predictions_clusters | prediction cluster counts | cluster_count_threshold | reduced_clusters \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "###################################################\n",
    "\n",
    "def run_preclustering(model, scan_path, labels_dict=None, sample_tag=\"\", inst_seg_img_dir_path=\"./plots/inst_seg/\", cls_seg_img_dir_path=\"./plots/cls_seg/\"):\n",
    "    \"\"\"\n",
    "    Runs the scan through the model\n",
    "    Filters out the background predictions\n",
    "    Plots cls and inst predictions post filtering and saves plots to file\n",
    "    Returns the Nx5 data of non-background points --> x|y|z|cls|inst\n",
    "    \"\"\"\n",
    "    # KX5 array --> x|y|z|cls|inst\n",
    "    scan_data, _ = classify_scan(model, scan_path, verbose=True)\n",
    "    \n",
    "    # non bg NX5 array --> x|y|z|cls|inst\n",
    "    scan_data, _ = filter_out_background(scan_data)\n",
    "    \n",
    "    ## [RED FLAG] - No use of the cluster_count or data\n",
    "    _, cluster_data = count_cluster_by_instance_prediction(scan_data)\n",
    "    \n",
    "    ## [RED FLAG] what if dir_path specified as None. Need to catch this cas\n",
    "    save_prediction_plots(scan_data, cls_tag=sample_tag, inst_tag=sample_tag, cls_seg_dir_path=cls_seg_img_dir_path, inst_seg_dir_path=inst_seg_img_dir_path, labels_dict=labels_dict)\n",
    "    return scan_data, {\"0_scan\": scan_path, \"0_tag\":sample_tag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0ada12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Set up model\n",
    "# myDetector = Detector(model_params=\"_model/train1-fix3/2023_06_30_09_56_12/params_epoch488_for_min_test_loss.pt\")\n",
    "\n",
    "# ## Looping through the test set\n",
    "# ## TEMP: single sample\n",
    "# scan_path = \"./_data/scans/LH-3-231201600-Pass-2023_06_12-9-38-37-588.ply\"\n",
    "# result = myDetector.process_sample(scan_path)\n",
    "# print(result)\n",
    "# ## For each scan in test set, run the classification prediction\n",
    "# ## Plot and save images for each \n",
    "# ## collate losses: --> scan name: instance seg loss, class seg loss\n",
    "\n",
    "\n",
    "# ## For each scan in training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57b4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test Running a sample\n",
    "\n",
    "# ## Run Settings\n",
    "# model_params_path = \"./_model/train1-fix3/2023_06_22_17_01_13/params_epoch497_for_min_test_loss.pt\"\n",
    "# scan_path = \"./_data/scans/LH-3-231201600-Pass-2023_06_12-9-38-37-588.ply\"\n",
    "# sample_name = \"LH-3-231201600-Pass-2023_06_12-9-38-37-588\"\n",
    "\n",
    "# ## Instantiating model and running scan through for predictions\n",
    "# model = configure_model(model_params_path, verbose=True)\n",
    "# scan_data, _ = classify_scan(model, scan_path, verbose=True)\n",
    "# print(\"scan_data.shape :\")\n",
    "# print(scan_data.shape)\n",
    "# print()\n",
    "\n",
    "\n",
    "# ## Filter out background points\n",
    "# scan_data, _ = filter_out_background(scan_data)\n",
    "# print(\"scan_data.shape :\")\n",
    "# print(scan_data.shape)\n",
    "# print()\n",
    "\n",
    "# ## Clustering by the instance predictions\n",
    "# cluster_count, cluster_data = count_cluster_by_instance_prediction(scan_data)\n",
    "# print(\"cluster_count: \")\n",
    "# print(cluster_count)\n",
    "# print()\n",
    "# print(\"cluster_data: \")\n",
    "# print(cluster_data)\n",
    "# print()\n",
    "\n",
    "# # ## Plotting class predictions and instance predictions\n",
    "# # save_prediction_plots(scan_data, cls_tag='egA_xycls', inst_tag='egA_xyinst')\n",
    "\n",
    "# inst_seg_img_directory = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_img_instance_seg/\"\n",
    "# cls_seg_img_directory = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_img_class_seg/\"\n",
    "# save_prediction_plots(scan_data, cls_tag=sample_name, inst_tag=sample_name, cls_seg_dir_path=cls_seg_img_directory, inst_seg_dir_path=inst_seg_img_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5bdc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test Running a sample\n",
    "\n",
    "# ## Run Settings\n",
    "# model_params_path = \"./_model/train1-fix3/2023_06_22_17_01_13/params_epoch497_for_min_test_loss.pt\"\n",
    "# scan_path = \"./_data/scans/LH-3-231201600-Pass-2023_06_12-9-38-37-588.ply\"\n",
    "# sample_name = \"LH-3-231201600-Pass-2023_06_12-9-38-37-588\"\n",
    "\n",
    "# ## Instantiating model and running scan through for predictions and plots on predictions\n",
    "# model = configure_model(model_params_path, verbose=True)\n",
    "\n",
    "# inst_seg_img_directory = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_img_instance_seg/\"\n",
    "# cls_seg_img_directory = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_img_class_seg/\"\n",
    "# run_preclustering(model, scan_path, sample_tag=sample_name, inst_seg_img_dir_path=inst_seg_img_directory, cls_seg_img_dir_path=cls_seg_img_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5ecaac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74245c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Setup Time (secs) : 0.5708363056182861\n",
      "Scan Inference Time (secs):  10.51757287979126\n",
      "\n",
      "Scan Inference Time (secs):  10.537972688674927\n",
      "\n",
      "Scan Inference Time (secs):  10.738929271697998\n",
      "\n",
      "Scan Inference Time (secs):  10.024059772491455\n",
      "\n",
      "Scan Inference Time (secs):  10.495957612991333\n",
      "\n",
      "Scan Inference Time (secs):  9.566447734832764\n",
      "\n",
      "Scan Inference Time (secs):  9.555433988571167\n",
      "\n",
      "Scan Inference Time (secs):  8.909443855285645\n",
      "\n",
      "Scan Inference Time (secs):  9.63809871673584\n",
      "\n",
      "Scan Inference Time (secs):  9.579296112060547\n",
      "\n",
      "Scan Inference Time (secs):  10.271457433700562\n",
      "\n",
      "Scan Inference Time (secs):  10.109545469284058\n",
      "\n",
      "Scan Inference Time (secs):  9.335759162902832\n",
      "\n",
      "Scan Inference Time (secs):  10.822887420654297\n",
      "\n",
      "Scan Inference Time (secs):  9.290156364440918\n",
      "\n",
      "Scan Inference Time (secs):  9.180329084396362\n",
      "\n",
      "Scan Inference Time (secs):  9.76867413520813\n",
      "\n",
      "Scan Inference Time (secs):  9.844476222991943\n",
      "\n",
      "Scan Inference Time (secs):  9.917199850082397\n",
      "\n",
      "Scan Inference Time (secs):  9.754975080490112\n",
      "\n",
      "Scan Inference Time (secs):  10.341258764266968\n",
      "\n",
      "Scan Inference Time (secs):  11.740347862243652\n",
      "\n",
      "Scan Inference Time (secs):  10.80525517463684\n",
      "\n",
      "Scan Inference Time (secs):  9.662057161331177\n",
      "\n",
      "Scan Inference Time (secs):  10.660804986953735\n",
      "\n",
      "Scan Inference Time (secs):  9.690244913101196\n",
      "\n",
      "Scan Inference Time (secs):  9.598433017730713\n",
      "\n",
      "Scan Inference Time (secs):  9.631264686584473\n",
      "\n",
      "Scan Inference Time (secs):  9.935803413391113\n",
      "\n",
      "Scan Inference Time (secs):  9.559043645858765\n",
      "\n",
      "Scan Inference Time (secs):  9.723209619522095\n",
      "\n",
      "Scan Inference Time (secs):  9.282449960708618\n",
      "\n",
      "Scan Inference Time (secs):  10.55331301689148\n",
      "\n",
      "Scan Inference Time (secs):  9.978449821472168\n",
      "\n",
      "Scan Inference Time (secs):  9.291871786117554\n",
      "\n",
      "Scan Inference Time (secs):  10.132188320159912\n",
      "\n",
      "Scan Inference Time (secs):  10.078414916992188\n",
      "\n",
      "Scan Inference Time (secs):  9.77884030342102\n",
      "\n",
      "Scan Inference Time (secs):  9.259949922561646\n",
      "\n",
      "Scan Inference Time (secs):  9.648421287536621\n",
      "\n",
      "Scan Inference Time (secs):  9.45401668548584\n",
      "\n",
      "Scan Inference Time (secs):  9.41296648979187\n",
      "\n",
      "Scan Inference Time (secs):  9.685953855514526\n",
      "\n",
      "Scan Inference Time (secs):  9.091167688369751\n",
      "\n",
      "Scan Inference Time (secs):  9.202969074249268\n",
      "\n",
      "Scan Inference Time (secs):  8.864700555801392\n",
      "\n",
      "Scan Inference Time (secs):  9.853184461593628\n",
      "\n",
      "Scan Inference Time (secs):  10.467661142349243\n",
      "\n",
      "Scan Inference Time (secs):  9.393105268478394\n",
      "\n",
      "Scan Inference Time (secs):  9.308634757995605\n",
      "\n",
      "Scan Inference Time (secs):  9.654519081115723\n",
      "\n",
      "Scan Inference Time (secs):  9.482776880264282\n",
      "\n",
      "Scan Inference Time (secs):  9.759705543518066\n",
      "\n",
      "Scan Inference Time (secs):  9.237589836120605\n",
      "\n",
      "Scan Inference Time (secs):  9.65362286567688\n",
      "\n",
      "Scan Inference Time (secs):  9.085707426071167\n",
      "\n",
      "Scan Inference Time (secs):  9.513448476791382\n",
      "\n",
      "Scan Inference Time (secs):  9.388827562332153\n",
      "\n",
      "Scan Inference Time (secs):  9.18362283706665\n",
      "\n",
      "Scan Inference Time (secs):  10.373265981674194\n",
      "\n",
      "Scan Inference Time (secs):  9.974101305007935\n",
      "\n",
      "Scan Inference Time (secs):  10.518616676330566\n",
      "\n",
      "Scan Inference Time (secs):  9.717076778411865\n",
      "\n",
      "Scan Inference Time (secs):  9.378717184066772\n",
      "\n",
      "Scan Inference Time (secs):  9.66016173362732\n",
      "\n",
      "Scan Inference Time (secs):  9.76073694229126\n",
      "\n",
      "Scan Inference Time (secs):  9.891353368759155\n",
      "\n",
      "Scan Inference Time (secs):  10.308730602264404\n",
      "\n",
      "Scan Inference Time (secs):  10.340574026107788\n",
      "\n",
      "Scan Inference Time (secs):  9.69228482246399\n",
      "\n",
      "Scan Inference Time (secs):  10.245009660720825\n",
      "\n",
      "Scan Inference Time (secs):  10.03852367401123\n",
      "\n",
      "Scan Inference Time (secs):  9.644179821014404\n",
      "\n",
      "Scan Inference Time (secs):  9.736594915390015\n",
      "\n",
      "Scan Inference Time (secs):  9.389962196350098\n",
      "\n",
      "Scan Inference Time (secs):  9.530672311782837\n",
      "\n",
      "Scan Inference Time (secs):  9.538403272628784\n",
      "\n",
      "Scan Inference Time (secs):  10.926605463027954\n",
      "\n",
      "Scan Inference Time (secs):  9.416148662567139\n",
      "\n",
      "Scan Inference Time (secs):  9.621226787567139\n",
      "\n",
      "Scan Inference Time (secs):  9.88066029548645\n",
      "\n",
      "Scan Inference Time (secs):  9.30348539352417\n",
      "\n",
      "Scan Inference Time (secs):  9.668842077255249\n",
      "\n",
      "Scan Inference Time (secs):  9.787414073944092\n",
      "\n",
      "Scan Inference Time (secs):  9.836842060089111\n",
      "\n",
      "Scan Inference Time (secs):  9.459232568740845\n",
      "\n",
      "Scan Inference Time (secs):  9.294451475143433\n",
      "\n",
      "Scan Inference Time (secs):  9.32740592956543\n",
      "\n",
      "Scan Inference Time (secs):  9.640575885772705\n",
      "\n",
      "Scan Inference Time (secs):  9.806949853897095\n",
      "\n",
      "Scan Inference Time (secs):  9.657560110092163\n",
      "\n",
      "Scan Inference Time (secs):  9.612224340438843\n",
      "\n",
      "Scan Inference Time (secs):  10.343241214752197\n",
      "\n",
      "Scan Inference Time (secs):  10.019337177276611\n",
      "\n",
      "Scan Inference Time (secs):  9.807200193405151\n",
      "\n",
      "Scan Inference Time (secs):  9.542912721633911\n",
      "\n",
      "Scan Inference Time (secs):  9.644028425216675\n",
      "\n",
      "Scan Inference Time (secs):  11.506478309631348\n",
      "\n",
      "Scan Inference Time (secs):  12.554582834243774\n",
      "\n",
      "Scan Inference Time (secs):  9.995633840560913\n",
      "\n",
      "Scan Inference Time (secs):  9.891216039657593\n",
      "\n",
      "Scan Inference Time (secs):  9.596331596374512\n",
      "\n",
      "Scan Inference Time (secs):  9.139741897583008\n",
      "\n",
      "Scan Inference Time (secs):  10.456207752227783\n",
      "\n",
      "Scan Inference Time (secs):  9.885774612426758\n",
      "\n",
      "Scan Inference Time (secs):  9.64053225517273\n",
      "\n",
      "Scan Inference Time (secs):  9.282537698745728\n",
      "\n",
      "Scan Inference Time (secs):  9.758522033691406\n",
      "\n",
      "Scan Inference Time (secs):  9.19755220413208\n",
      "\n",
      "Scan Inference Time (secs):  9.741153001785278\n",
      "\n",
      "Scan Inference Time (secs):  10.063307762145996\n",
      "\n",
      "Scan Inference Time (secs):  9.264651536941528\n",
      "\n",
      "Scan Inference Time (secs):  9.536453485488892\n",
      "\n",
      "Scan Inference Time (secs):  9.759206771850586\n",
      "\n",
      "Scan Inference Time (secs):  10.680715560913086\n",
      "\n",
      "Scan Inference Time (secs):  9.95324444770813\n",
      "\n",
      "Scan Inference Time (secs):  9.157808542251587\n",
      "\n",
      "Scan Inference Time (secs):  9.498416423797607\n",
      "\n",
      "Scan Inference Time (secs):  9.013888359069824\n",
      "\n",
      "Scan Inference Time (secs):  9.465928792953491\n",
      "\n",
      "Scan Inference Time (secs):  9.689916849136353\n",
      "\n",
      "Scan Inference Time (secs):  9.926344156265259\n",
      "\n",
      "Scan Inference Time (secs):  8.93008804321289\n",
      "\n",
      "Scan Inference Time (secs):  9.568154096603394\n",
      "\n",
      "Scan Inference Time (secs):  9.697864055633545\n",
      "\n",
      "Scan Inference Time (secs):  9.302908182144165\n",
      "\n",
      "Scan Inference Time (secs):  10.711666107177734\n",
      "\n",
      "Scan Inference Time (secs):  9.473455429077148\n",
      "\n",
      "Scan Inference Time (secs):  9.913766860961914\n",
      "\n",
      "Scan Inference Time (secs):  9.466434240341187\n",
      "\n",
      "Scan Inference Time (secs):  9.406333446502686\n",
      "\n",
      "Scan Inference Time (secs):  9.261607646942139\n",
      "\n",
      "Scan Inference Time (secs):  9.216562509536743\n",
      "\n",
      "Scan Inference Time (secs):  9.70467209815979\n",
      "\n",
      "Scan Inference Time (secs):  9.490617513656616\n",
      "\n",
      "Scan Inference Time (secs):  9.607858419418335\n",
      "\n",
      "Scan Inference Time (secs):  8.55367374420166\n",
      "\n",
      "Scan Inference Time (secs):  9.757207870483398\n",
      "\n",
      "Scan Inference Time (secs):  9.642222166061401\n",
      "\n",
      "Scan Inference Time (secs):  10.16073489189148\n",
      "\n",
      "Scan Inference Time (secs):  9.494333267211914\n",
      "\n",
      "Scan Inference Time (secs):  9.625820636749268\n",
      "\n",
      "Scan Inference Time (secs):  9.247368812561035\n",
      "\n",
      "Scan Inference Time (secs):  9.9709951877594\n",
      "\n",
      "Scan Inference Time (secs):  9.831883907318115\n",
      "\n",
      "Scan Inference Time (secs):  9.747866868972778\n",
      "\n",
      "Scan Inference Time (secs):  9.707152128219604\n",
      "\n",
      "Scan Inference Time (secs):  9.855249166488647\n",
      "\n",
      "Scan Inference Time (secs):  9.448340654373169\n",
      "\n",
      "Scan Inference Time (secs):  9.79147219657898\n",
      "\n",
      "Scan Inference Time (secs):  9.54668378829956\n",
      "\n",
      "Scan Inference Time (secs):  9.47575306892395\n",
      "\n",
      "Scan Inference Time (secs):  9.465286016464233\n",
      "\n",
      "Scan Inference Time (secs):  9.55814790725708\n",
      "\n",
      "Scan Inference Time (secs):  10.382022380828857\n",
      "\n",
      "Scan Inference Time (secs):  9.392792463302612\n",
      "\n",
      "Scan Inference Time (secs):  11.765421152114868\n",
      "\n",
      "Scan Inference Time (secs):  10.176279306411743\n",
      "\n",
      "Scan Inference Time (secs):  9.837330102920532\n",
      "\n",
      "Scan Inference Time (secs):  9.510080337524414\n",
      "\n",
      "Scan Inference Time (secs):  9.23259425163269\n",
      "\n",
      "Scan Inference Time (secs):  9.758642673492432\n",
      "\n",
      "Scan Inference Time (secs):  9.43067455291748\n",
      "\n",
      "Scan Inference Time (secs):  9.599582433700562\n",
      "\n",
      "Scan Inference Time (secs):  9.137491703033447\n",
      "\n",
      "Scan Inference Time (secs):  9.661216020584106\n",
      "\n",
      "Scan Inference Time (secs):  10.48445439338684\n",
      "\n",
      "Scan Inference Time (secs):  9.569512367248535\n",
      "\n",
      "Scan Inference Time (secs):  9.498823404312134\n",
      "\n",
      "Scan Inference Time (secs):  9.556954145431519\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Inference Time (secs):  9.69490909576416\n",
      "\n",
      "Scan Inference Time (secs):  9.257021427154541\n",
      "\n",
      "Scan Inference Time (secs):  10.008171319961548\n",
      "\n",
      "Scan Inference Time (secs):  10.716116428375244\n",
      "\n",
      "Scan Inference Time (secs):  9.921858549118042\n",
      "\n",
      "Scan Inference Time (secs):  10.966448545455933\n",
      "\n",
      "Scan Inference Time (secs):  11.05726671218872\n",
      "\n",
      "Scan Inference Time (secs):  11.185437202453613\n",
      "\n",
      "Scan Inference Time (secs):  10.644825220108032\n",
      "\n",
      "Scan Inference Time (secs):  9.851844310760498\n",
      "\n",
      "Scan Inference Time (secs):  9.41592288017273\n",
      "\n",
      "Scan Inference Time (secs):  9.634252071380615\n",
      "\n",
      "Scan Inference Time (secs):  9.897159814834595\n",
      "\n",
      "Scan Inference Time (secs):  9.717150449752808\n",
      "\n",
      "Scan Inference Time (secs):  9.371872186660767\n",
      "\n",
      "Scan Inference Time (secs):  9.813512325286865\n",
      "\n",
      "Scan Inference Time (secs):  9.380998373031616\n",
      "\n",
      "Scan Inference Time (secs):  9.491893291473389\n",
      "\n",
      "Scan Inference Time (secs):  11.543368816375732\n",
      "\n",
      "Scan Inference Time (secs):  10.116774082183838\n",
      "\n",
      "Scan Inference Time (secs):  9.502047061920166\n",
      "\n",
      "Scan Inference Time (secs):  10.718185424804688\n",
      "\n",
      "Scan Inference Time (secs):  9.66672968864441\n",
      "\n",
      "Scan Inference Time (secs):  9.648138761520386\n",
      "\n",
      "Scan Inference Time (secs):  9.65613865852356\n",
      "\n",
      "Scan Inference Time (secs):  9.38054633140564\n",
      "\n",
      "Scan Inference Time (secs):  9.710545539855957\n",
      "\n",
      "Scan Inference Time (secs):  9.616891145706177\n",
      "\n",
      "Scan Inference Time (secs):  9.518452405929565\n",
      "\n",
      "Scan Inference Time (secs):  9.98818564414978\n",
      "\n",
      "Scan Inference Time (secs):  10.333982229232788\n",
      "\n",
      "Scan Inference Time (secs):  9.599270582199097\n",
      "\n",
      "Scan Inference Time (secs):  9.774370193481445\n",
      "\n",
      "Scan Inference Time (secs):  9.659986019134521\n",
      "\n",
      "Scan Inference Time (secs):  9.788006782531738\n",
      "\n",
      "Scan Inference Time (secs):  9.10572338104248\n",
      "\n",
      "Scan Inference Time (secs):  10.0433669090271\n",
      "\n",
      "Scan Inference Time (secs):  8.910866498947144\n",
      "\n",
      "Scan Inference Time (secs):  9.278120994567871\n",
      "\n",
      "Scan Inference Time (secs):  9.231490135192871\n",
      "\n",
      "Scan Inference Time (secs):  8.739418983459473\n",
      "\n",
      "Scan Inference Time (secs):  9.991044759750366\n",
      "\n",
      "Scan Inference Time (secs):  11.251296520233154\n",
      "\n",
      "Scan Inference Time (secs):  11.006893396377563\n",
      "\n",
      "Scan Inference Time (secs):  9.761163234710693\n",
      "\n",
      "Scan Inference Time (secs):  9.023772239685059\n",
      "\n",
      "Scan Inference Time (secs):  9.633541107177734\n",
      "\n",
      "Scan Inference Time (secs):  9.757484674453735\n",
      "\n",
      "Scan Inference Time (secs):  9.560317754745483\n",
      "\n",
      "Scan Inference Time (secs):  9.421746015548706\n",
      "\n",
      "Scan Inference Time (secs):  9.566713094711304\n",
      "\n",
      "Scan Inference Time (secs):  9.355931282043457\n",
      "\n",
      "Scan Inference Time (secs):  9.525953531265259\n",
      "\n",
      "Scan Inference Time (secs):  10.014435052871704\n",
      "\n",
      "Scan Inference Time (secs):  9.324549913406372\n",
      "\n",
      "Scan Inference Time (secs):  9.798532009124756\n",
      "\n",
      "Scan Inference Time (secs):  8.74368691444397\n",
      "\n",
      "Scan Inference Time (secs):  9.144482135772705\n",
      "\n",
      "Scan Inference Time (secs):  9.231663465499878\n",
      "\n",
      "Scan Inference Time (secs):  9.524457931518555\n",
      "\n",
      "Scan Inference Time (secs):  9.699972152709961\n",
      "\n",
      "Scan Inference Time (secs):  9.483621835708618\n",
      "\n",
      "Scan Inference Time (secs):  8.79170274734497\n",
      "\n",
      "Scan Inference Time (secs):  9.810059309005737\n",
      "\n",
      "Scan Inference Time (secs):  9.333268165588379\n",
      "\n",
      "Scan Inference Time (secs):  9.632551193237305\n",
      "\n",
      "Scan Inference Time (secs):  9.420753479003906\n",
      "\n",
      "Scan Inference Time (secs):  9.830374479293823\n",
      "\n",
      "Scan Inference Time (secs):  10.430294036865234\n",
      "\n",
      "Scan Inference Time (secs):  9.551325798034668\n",
      "\n",
      "Scan Inference Time (secs):  8.692239046096802\n",
      "\n",
      "Scan Inference Time (secs):  10.037083387374878\n",
      "\n",
      "Scan Inference Time (secs):  9.571794509887695\n",
      "\n",
      "Scan Inference Time (secs):  10.31144404411316\n",
      "\n",
      "Scan Inference Time (secs):  9.82990312576294\n",
      "\n",
      "Scan Inference Time (secs):  9.21470332145691\n",
      "\n",
      "Scan Inference Time (secs):  10.680882930755615\n",
      "\n",
      "Scan Inference Time (secs):  9.654567003250122\n",
      "\n",
      "Scan Inference Time (secs):  9.102979898452759\n",
      "\n",
      "Scan Inference Time (secs):  9.955249547958374\n",
      "\n",
      "Scan Inference Time (secs):  9.834803581237793\n",
      "\n",
      "Scan Inference Time (secs):  8.91896939277649\n",
      "\n",
      "Scan Inference Time (secs):  10.280062437057495\n",
      "\n",
      "Scan Inference Time (secs):  9.61606764793396\n",
      "\n",
      "Scan Inference Time (secs):  9.754017114639282\n",
      "\n",
      "Scan Inference Time (secs):  10.330349922180176\n",
      "\n",
      "Scan Inference Time (secs):  9.954794883728027\n",
      "\n",
      "Scan Inference Time (secs):  9.795109748840332\n",
      "\n",
      "Scan Inference Time (secs):  9.73835015296936\n",
      "\n",
      "Scan Inference Time (secs):  10.407763719558716\n",
      "\n",
      "Scan Inference Time (secs):  9.682739734649658\n",
      "\n",
      "Scan Inference Time (secs):  12.340839147567749\n",
      "\n",
      "Scan Inference Time (secs):  9.587158918380737\n",
      "\n",
      "Scan Inference Time (secs):  9.778762102127075\n",
      "\n",
      "Scan Inference Time (secs):  9.553501605987549\n",
      "\n",
      "Scan Inference Time (secs):  9.593300342559814\n",
      "\n",
      "Scan Inference Time (secs):  9.38228178024292\n",
      "\n",
      "Scan Inference Time (secs):  9.62178373336792\n",
      "\n",
      "Scan Inference Time (secs):  9.619422435760498\n",
      "\n",
      "Scan Inference Time (secs):  9.57468843460083\n",
      "\n",
      "Scan Inference Time (secs):  9.391672134399414\n",
      "\n",
      "Scan Inference Time (secs):  10.774030208587646\n",
      "\n",
      "Scan Inference Time (secs):  9.949668407440186\n",
      "\n",
      "Scan Inference Time (secs):  9.730746507644653\n",
      "\n",
      "Scan Inference Time (secs):  9.632310152053833\n",
      "\n",
      "Scan Inference Time (secs):  9.72745966911316\n",
      "\n",
      "Scan Inference Time (secs):  10.274931192398071\n",
      "\n",
      "Scan Inference Time (secs):  10.387194156646729\n",
      "\n",
      "Scan Inference Time (secs):  10.248626232147217\n",
      "\n",
      "Scan Inference Time (secs):  10.463273286819458\n",
      "\n",
      "Scan Inference Time (secs):  10.141132831573486\n",
      "\n",
      "Scan Inference Time (secs):  9.509928941726685\n",
      "\n",
      "Scan Inference Time (secs):  10.235251188278198\n",
      "\n",
      "Scan Inference Time (secs):  10.021369218826294\n",
      "\n",
      "Scan Inference Time (secs):  10.127807140350342\n",
      "\n",
      "Scan Inference Time (secs):  9.544733762741089\n",
      "\n",
      "Scan Inference Time (secs):  9.963309288024902\n",
      "\n",
      "Scan Inference Time (secs):  9.631690979003906\n",
      "\n",
      "Scan Inference Time (secs):  10.945443391799927\n",
      "\n",
      "Scan Inference Time (secs):  9.595067262649536\n",
      "\n",
      "Scan Inference Time (secs):  9.652619361877441\n",
      "\n",
      "Scan Inference Time (secs):  9.396880865097046\n",
      "\n",
      "Scan Inference Time (secs):  10.036036968231201\n",
      "\n",
      "Scan Inference Time (secs):  10.165132999420166\n",
      "\n",
      "Scan Inference Time (secs):  9.731744289398193\n",
      "\n",
      "Scan Inference Time (secs):  10.004269123077393\n",
      "\n",
      "Scan Inference Time (secs):  9.304262161254883\n",
      "\n",
      "Scan Inference Time (secs):  9.42756175994873\n",
      "\n",
      "Scan Inference Time (secs):  9.648221731185913\n",
      "\n",
      "Scan Inference Time (secs):  9.586775779724121\n",
      "\n",
      "Scan Inference Time (secs):  9.619445562362671\n",
      "\n",
      "Scan Inference Time (secs):  10.502285957336426\n",
      "\n",
      "Scan Inference Time (secs):  10.619812726974487\n",
      "\n",
      "Scan Inference Time (secs):  9.909015655517578\n",
      "\n",
      "Scan Inference Time (secs):  10.793487071990967\n",
      "\n",
      "Scan Inference Time (secs):  10.53718113899231\n",
      "\n",
      "Scan Inference Time (secs):  9.804609775543213\n",
      "\n",
      "Scan Inference Time (secs):  9.706177949905396\n",
      "\n",
      "Scan Inference Time (secs):  10.296947717666626\n",
      "\n",
      "Scan Inference Time (secs):  12.308200120925903\n",
      "\n",
      "Scan Inference Time (secs):  9.172075748443604\n",
      "\n",
      "Scan Inference Time (secs):  9.684518814086914\n",
      "\n",
      "Scan Inference Time (secs):  9.75195598602295\n",
      "\n",
      "Scan Inference Time (secs):  11.090171813964844\n",
      "\n",
      "Scan Inference Time (secs):  10.474508285522461\n",
      "\n",
      "Scan Inference Time (secs):  10.001375198364258\n",
      "\n",
      "Scan Inference Time (secs):  9.313941478729248\n",
      "\n",
      "Scan Inference Time (secs):  10.572412490844727\n",
      "\n",
      "Scan Inference Time (secs):  8.869247436523438\n",
      "\n",
      "Scan Inference Time (secs):  10.458342552185059\n",
      "\n",
      "Scan Inference Time (secs):  10.027291536331177\n",
      "\n",
      "Scan Inference Time (secs):  9.381863117218018\n",
      "\n",
      "Scan Inference Time (secs):  9.876765966415405\n",
      "\n",
      "Scan Inference Time (secs):  10.091754674911499\n",
      "\n",
      "Scan Inference Time (secs):  10.200939416885376\n",
      "\n",
      "Scan Inference Time (secs):  10.847339630126953\n",
      "\n",
      "Scan Inference Time (secs):  10.02863597869873\n",
      "\n",
      "Scan Inference Time (secs):  12.199876546859741\n",
      "\n",
      "Scan Inference Time (secs):  10.363857984542847\n",
      "\n",
      "Scan Inference Time (secs):  11.225736856460571\n",
      "\n",
      "Scan Inference Time (secs):  9.497844934463501\n",
      "\n",
      "Scan Inference Time (secs):  10.016981840133667\n",
      "\n",
      "Scan Inference Time (secs):  9.34893274307251\n",
      "\n",
      "Scan Inference Time (secs):  9.09388017654419\n",
      "\n",
      "Scan Inference Time (secs):  11.486611366271973\n",
      "\n",
      "Scan Inference Time (secs):  9.748437404632568\n",
      "\n",
      "Scan Inference Time (secs):  10.298961400985718\n",
      "\n",
      "Scan Inference Time (secs):  9.125853061676025\n",
      "\n",
      "Scan Inference Time (secs):  9.948805570602417\n",
      "\n",
      "Scan Inference Time (secs):  11.0713050365448\n",
      "\n",
      "Scan Inference Time (secs):  9.67323613166809\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Inference Time (secs):  10.447551012039185\n",
      "\n",
      "Scan Inference Time (secs):  9.663655757904053\n",
      "\n",
      "Scan Inference Time (secs):  9.694123983383179\n",
      "\n",
      "Scan Inference Time (secs):  10.20733380317688\n",
      "\n",
      "Scan Inference Time (secs):  10.22365117073059\n",
      "\n",
      "Scan Inference Time (secs):  10.060018062591553\n",
      "\n",
      "Scan Inference Time (secs):  9.614469766616821\n",
      "\n",
      "Scan Inference Time (secs):  10.41034722328186\n",
      "\n",
      "Scan Inference Time (secs):  9.412639141082764\n",
      "\n",
      "Scan Inference Time (secs):  9.73371410369873\n",
      "\n",
      "Scan Inference Time (secs):  9.594569206237793\n",
      "\n",
      "Scan Inference Time (secs):  9.70112943649292\n",
      "\n",
      "Scan Inference Time (secs):  10.229320764541626\n",
      "\n",
      "Scan Inference Time (secs):  9.212526798248291\n",
      "\n",
      "Scan Inference Time (secs):  9.98763918876648\n",
      "\n",
      "Scan Inference Time (secs):  9.619618892669678\n",
      "\n",
      "Scan Inference Time (secs):  9.73998475074768\n",
      "\n",
      "Scan Inference Time (secs):  8.77487063407898\n",
      "\n",
      "Scan Inference Time (secs):  11.040887355804443\n",
      "\n",
      "Scan Inference Time (secs):  9.928213834762573\n",
      "\n",
      "Scan Inference Time (secs):  9.604512691497803\n",
      "\n",
      "Scan Inference Time (secs):  9.612840414047241\n",
      "\n",
      "Scan Inference Time (secs):  11.07511568069458\n",
      "\n",
      "Scan Inference Time (secs):  9.6923189163208\n",
      "\n",
      "Scan Inference Time (secs):  9.703129291534424\n",
      "\n",
      "Scan Inference Time (secs):  9.599842309951782\n",
      "\n",
      "Scan Inference Time (secs):  8.798721075057983\n",
      "\n",
      "Scan Inference Time (secs):  9.886332750320435\n",
      "\n",
      "Scan Inference Time (secs):  9.835215330123901\n",
      "\n",
      "Scan Inference Time (secs):  10.041228532791138\n",
      "\n",
      "Scan Inference Time (secs):  9.529615640640259\n",
      "\n",
      "Scan Inference Time (secs):  9.838946342468262\n",
      "\n",
      "Scan Inference Time (secs):  9.27741265296936\n",
      "\n",
      "Scan Inference Time (secs):  9.769287109375\n",
      "\n",
      "Scan Inference Time (secs):  9.019171237945557\n",
      "\n",
      "Scan Inference Time (secs):  9.446921110153198\n",
      "\n",
      "Scan Inference Time (secs):  9.52531099319458\n",
      "\n",
      "Scan Inference Time (secs):  10.083187580108643\n",
      "\n",
      "Scan Inference Time (secs):  9.68738579750061\n",
      "\n",
      "Scan Inference Time (secs):  10.128798007965088\n",
      "\n",
      "Scan Inference Time (secs):  9.465395212173462\n",
      "\n",
      "Scan Inference Time (secs):  9.650036573410034\n",
      "\n",
      "Scan Inference Time (secs):  9.503106117248535\n",
      "\n",
      "Scan Inference Time (secs):  8.910819292068481\n",
      "\n",
      "Scan Inference Time (secs):  9.581085920333862\n",
      "\n",
      "Scan Inference Time (secs):  9.909680128097534\n",
      "\n",
      "Scan Inference Time (secs):  10.320038318634033\n",
      "\n",
      "Scan Inference Time (secs):  9.862414121627808\n",
      "\n",
      "Scan Inference Time (secs):  10.377717018127441\n",
      "\n",
      "Scan Inference Time (secs):  10.614691972732544\n",
      "\n",
      "Scan Inference Time (secs):  10.629087686538696\n",
      "\n",
      "Scan Inference Time (secs):  9.829891681671143\n",
      "\n",
      "Scan Inference Time (secs):  9.786228895187378\n",
      "\n",
      "Scan Inference Time (secs):  10.268309831619263\n",
      "\n",
      "Scan Inference Time (secs):  9.56416654586792\n",
      "\n",
      "Scan Inference Time (secs):  9.501081943511963\n",
      "\n",
      "Scan Inference Time (secs):  10.36610221862793\n",
      "\n",
      "Scan Inference Time (secs):  10.041887044906616\n",
      "\n",
      "Scan Inference Time (secs):  8.749104976654053\n",
      "\n",
      "Scan Inference Time (secs):  9.93325686454773\n",
      "\n",
      "Scan Inference Time (secs):  9.830098152160645\n",
      "\n",
      "Scan Inference Time (secs):  12.500438690185547\n",
      "\n",
      "Scan Inference Time (secs):  13.201080322265625\n",
      "\n",
      "Scan Inference Time (secs):  10.727097988128662\n",
      "\n",
      "Scan Inference Time (secs):  10.730916738510132\n",
      "\n",
      "Scan Inference Time (secs):  10.791359901428223\n",
      "\n",
      "Scan Inference Time (secs):  11.160364866256714\n",
      "\n",
      "Scan Inference Time (secs):  10.374610900878906\n",
      "\n",
      "Scan Inference Time (secs):  9.875937461853027\n",
      "\n",
      "Scan Inference Time (secs):  10.12497591972351\n",
      "\n",
      "Scan Inference Time (secs):  10.21337080001831\n",
      "\n",
      "Scan Inference Time (secs):  9.974931001663208\n",
      "\n",
      "Scan Inference Time (secs):  10.050309181213379\n",
      "\n",
      "Scan Inference Time (secs):  10.17322826385498\n",
      "\n",
      "Scan Inference Time (secs):  10.13092041015625\n",
      "\n",
      "Scan Inference Time (secs):  9.695054054260254\n",
      "\n",
      "Scan Inference Time (secs):  10.04625654220581\n",
      "\n",
      "Scan Inference Time (secs):  9.951992988586426\n",
      "\n",
      "Scan Inference Time (secs):  10.026178359985352\n",
      "\n",
      "Scan Inference Time (secs):  10.886510372161865\n",
      "\n",
      "Scan Inference Time (secs):  10.553585290908813\n",
      "\n",
      "Scan Inference Time (secs):  10.230827808380127\n",
      "\n",
      "Scan Inference Time (secs):  10.75204062461853\n",
      "\n",
      "Scan Inference Time (secs):  9.430015802383423\n",
      "\n",
      "Scan Inference Time (secs):  9.679245948791504\n",
      "\n",
      "Scan Inference Time (secs):  9.924517393112183\n",
      "\n",
      "Scan Inference Time (secs):  10.01150369644165\n",
      "\n",
      "Scan Inference Time (secs):  9.779342889785767\n",
      "\n",
      "Scan Inference Time (secs):  9.903221607208252\n",
      "\n",
      "Scan Inference Time (secs):  9.852042436599731\n",
      "\n",
      "Scan Inference Time (secs):  9.790024757385254\n",
      "\n",
      "Scan Inference Time (secs):  9.964847087860107\n",
      "\n",
      "Scan Inference Time (secs):  10.100140571594238\n",
      "\n",
      "Scan Inference Time (secs):  10.065940856933594\n",
      "\n",
      "Scan Inference Time (secs):  12.437961101531982\n",
      "\n",
      "Scan Inference Time (secs):  9.975282192230225\n",
      "\n",
      "Scan Inference Time (secs):  10.957384824752808\n",
      "\n",
      "Scan Inference Time (secs):  9.49480390548706\n",
      "\n",
      "Scan Inference Time (secs):  9.9510817527771\n",
      "\n",
      "Scan Inference Time (secs):  9.708497047424316\n",
      "\n",
      "Scan Inference Time (secs):  10.155813217163086\n",
      "\n",
      "Scan Inference Time (secs):  10.043176889419556\n",
      "\n",
      "Scan Inference Time (secs):  10.512486457824707\n",
      "\n",
      "Scan Inference Time (secs):  9.879296064376831\n",
      "\n",
      "Scan Inference Time (secs):  9.807191371917725\n",
      "\n",
      "Scan Inference Time (secs):  10.798071146011353\n",
      "\n",
      "Scan Inference Time (secs):  10.166347980499268\n",
      "\n",
      "Scan Inference Time (secs):  9.53376054763794\n",
      "\n",
      "Scan Inference Time (secs):  9.95959734916687\n",
      "\n",
      "Scan Inference Time (secs):  10.100990056991577\n",
      "\n",
      "Scan Inference Time (secs):  10.840827703475952\n",
      "\n",
      "Scan Inference Time (secs):  10.28986382484436\n",
      "\n",
      "Scan Inference Time (secs):  10.413518905639648\n",
      "\n",
      "Scan Inference Time (secs):  9.602447032928467\n",
      "\n",
      "Scan Inference Time (secs):  9.944777011871338\n",
      "\n",
      "Scan Inference Time (secs):  10.621802568435669\n",
      "\n",
      "Scan Inference Time (secs):  11.26876449584961\n",
      "\n",
      "Scan Inference Time (secs):  10.42705249786377\n",
      "\n",
      "Scan Inference Time (secs):  10.681995868682861\n",
      "\n",
      "Scan Inference Time (secs):  9.908198356628418\n",
      "\n",
      "Scan Inference Time (secs):  9.47502088546753\n",
      "\n",
      "Scan Inference Time (secs):  10.154041767120361\n",
      "\n",
      "Scan Inference Time (secs):  10.01407265663147\n",
      "\n",
      "Scan Inference Time (secs):  10.121196031570435\n",
      "\n",
      "Scan Inference Time (secs):  11.320029735565186\n",
      "\n",
      "Scan Inference Time (secs):  9.548731803894043\n",
      "\n",
      "Scan Inference Time (secs):  10.544183254241943\n",
      "\n",
      "Scan Inference Time (secs):  9.615386247634888\n",
      "\n",
      "Scan Inference Time (secs):  10.05924391746521\n",
      "\n",
      "Scan Inference Time (secs):  10.528632640838623\n",
      "\n",
      "Scan Inference Time (secs):  9.434602975845337\n",
      "\n",
      "Scan Inference Time (secs):  10.394261360168457\n",
      "\n",
      "Scan Inference Time (secs):  10.648225545883179\n",
      "\n",
      "Scan Inference Time (secs):  9.697487354278564\n",
      "\n",
      "Scan Inference Time (secs):  11.425577640533447\n",
      "\n",
      "Scan Inference Time (secs):  9.543524265289307\n",
      "\n",
      "Scan Inference Time (secs):  10.126246690750122\n",
      "\n",
      "Scan Inference Time (secs):  10.001407861709595\n",
      "\n",
      "Scan Inference Time (secs):  9.877307176589966\n",
      "\n",
      "Scan Inference Time (secs):  10.244343519210815\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Running inference on all the training and test samples and plotting results\n",
    "\n",
    "## Model Instantiating\n",
    "model_params_path = \"./_model/train1-fix3/2023_06_22_17_01_13/params_epoch497_for_min_test_loss.pt\"\n",
    "model = configure_model(model_params_path, verbose=True)\n",
    "\n",
    "\n",
    "# ## Looping through the test samples to generate and save plots\n",
    "# test_txt = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_data/test.txt\"\n",
    "# test_samples = parse_dataset_file(test_txt)\n",
    "\n",
    "# inst_seg_img_directory = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_img_instance_seg/test_set_with_label_overlay/\"\n",
    "# cls_seg_img_directory = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_img_class_seg/test_set_with_label_overlay/\"\n",
    "\n",
    "# for sample in test_samples:\n",
    "#     scan_path = sample[\"scan_path\"]\n",
    "#     sample_name = sample[\"name\"]\n",
    "#     label_path = sample[\"label_path\"]\n",
    "#     labels_dict = parse_labelfile(label_path)\n",
    "    \n",
    "#     run_preclustering(model, scan_path, labels_dict=labels_dict, sample_tag=sample_name, inst_seg_img_dir_path=inst_seg_img_directory, cls_seg_img_dir_path=cls_seg_img_directory)\n",
    "\n",
    "    \n",
    "## Looping through the train samples to generate and save plots\n",
    "train_txt = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_data/train.txt\"\n",
    "train_samples = parse_dataset_file(train_txt)\n",
    "\n",
    "inst_seg_img_directory = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_img_instance_seg/train_set/\"\n",
    "cls_seg_img_directory = \"C:/Users/KZTYLF/Documents/playground/GNN UIs/GNN InstanceSegmentation/Recreating Dataset/_img_class_seg/train_set/\"\n",
    "\n",
    "for sample in train_samples:\n",
    "    scan_path = sample[\"scan_path\"]\n",
    "    sample_name = sample[\"name\"]\n",
    "#     labels_dict = parse_labelfile(label_path)\n",
    "    \n",
    "    run_preclustering(model, scan_path, sample_tag=sample_name, inst_seg_img_dir_path=inst_seg_img_directory, cls_seg_img_dir_path=cls_seg_img_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85f6c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4], dtype=int64),)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(10)\n",
    "np.where(a < 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e32dc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
